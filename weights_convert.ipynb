{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandeep/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from lerobot.common.datasets.factory import make_dataset\n",
    "from lerobot.common.policies.factory import make_policy\n",
    "from lerobot.common.utils.utils import init_hydra_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 222 files: 100%|██████████| 222/222 [00:00<00:00, 3436.30it/s]\n",
      "WARNING:root:Hydra config is missing arguments: {'p_drop_emb', 'n_cond_layers', 'n_head', 'n_layer', 'do_mask_loss_for_padding', 'causal_attn', 'use_transformer', 'p_drop_attn', 'noise_scheduler_type'}\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ORIGINAL_WEIGHTS = \"/home/amandeep/latest_unet.ckpt\"\n",
    "# PATH_TO_CONFIG = \"/home/amandeep/lerobot/lerobot/configs/default.yaml\"\n",
    "PATH_TO_CONFIG = \"/home/amandeep/lerobot/unet_config.yaml\"\n",
    "PATH_TO_SAVE_NEW_WEIGHTS = \"../\"\n",
    "\n",
    "cfg = init_hydra_config(PATH_TO_CONFIG)\n",
    "\n",
    "policy = make_policy(cfg, dataset_stats=make_dataset(cfg).stats)\n",
    "\n",
    "state_dict = torch.load(PATH_TO_ORIGINAL_WEIGHTS)['state_dicts']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove keys based on what they start with.\n",
    "\n",
    "start_removals = [\"normalizer.\", \"obs_encoder.obs_nets.rgb.backbone.nets.0.nets.0\"]\n",
    "\n",
    "for to_remove in start_removals:\n",
    "    for k in list(state_dict.keys()):\n",
    "        if k.startswith(to_remove):\n",
    "            del state_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace keys based on what they start with.\n",
    "\n",
    "start_replacements = [\n",
    "    (\"obs_encoder.obs_nets.image.backbone.nets\", \"rgb_encoder.backbone\"),\n",
    "    (\"obs_encoder.obs_nets.image.pool\", \"rgb_encoder.pool\"),\n",
    "    (\"obs_encoder.obs_nets.image.nets.3\", \"rgb_encoder.out\"),\n",
    "    # *[(f\"model.up_modules.{i}.2.conv.\", f\"model.up_modules.{i}.2.\") for i in range(2)],\n",
    "    # *[(f\"model.down_modules.{i}.2.conv.\", f\"model.down_modules.{i}.2.\") for i in range(2)],\n",
    "    # *[\n",
    "    #     (f\"model.mid_modules.{i}.blocks.{k}.\", f\"model.mid_modules.{i}.conv{k + 1}.\")\n",
    "    #     for i, k in product(range(3), range(2))\n",
    "    # ],\n",
    "    # *[\n",
    "    #     (f\"model.down_modules.{i}.{j}.blocks.{k}.\", f\"model.down_modules.{i}.{j}.conv{k + 1}.\")\n",
    "    #     for i, j, k in product(range(3), range(2), range(2))\n",
    "    # ],\n",
    "    # *[\n",
    "    #     (f\"model.up_modules.{i}.{j}.blocks.{k}.\", f\"model.up_modules.{i}.{j}.conv{k + 1}.\")\n",
    "    #     for i, j, k in product(range(3), range(2), range(2))\n",
    "    # ],\n",
    "    (\"model.\", \"net.\")\n",
    "]\n",
    "\n",
    "for to_replace, replace_with in start_replacements:\n",
    "    for k in list(state_dict.keys()):\n",
    "        if k.startswith(to_replace):\n",
    "            k_ = replace_with + k.removeprefix(to_replace)\n",
    "            state_dict[k_] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "\n",
    "pos_y = state_dict['rgb_encoder.pool.pos_y'].t()\n",
    "pos_x = state_dict['rgb_encoder.pool.pos_x'].t()\n",
    "pos_grid = torch.cat([pos_x, pos_y], dim=1)\n",
    "state_dict['rgb_encoder.pool.pos_grid'] = pos_grid\n",
    "\n",
    "missing_keys, unexpected_keys = policy.diffusion.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED KEYS\n",
      "rgb_encoder.pool.pos_y\n",
      "rgb_encoder.pool.temperature\n",
      "net._dummy_variable\n",
      "rgb_encoder.pool.pos_x\n"
     ]
    }
   ],
   "source": [
    "unexpected_keys = set(unexpected_keys)\n",
    "allowed_unexpected_keys = eval(\n",
    "    \"{'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.1.nets.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.1.pos_x', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.1.nets.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn1.weight', '_dummy_variable', 'mask_generator._dummy_variable', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.1.temperature', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.1.pos_y', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn2.bias'}\"\n",
    ")\n",
    "if len(missing_keys) != 0:\n",
    "    print(\"MISSING KEYS\")\n",
    "    print(missing_keys)\n",
    "if unexpected_keys != allowed_unexpected_keys:\n",
    "    print(\"UNEXPECTED KEYS\")\n",
    "    for k in unexpected_keys:\n",
    "        if(k not in allowed_unexpected_keys):\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_keys = set(unexpected_keys)\n",
    "allowed_unexpected_keys = eval(\n",
    "    \"{'rgb_encoder.pool.pos_y','rgb_encoder.pool.temperature','net._dummy_variable','rgb_encoder.pool.pos_x','obs_encoder.obs_nets.image.nets.0.nets.7.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.1.nets.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.1.pos_x', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.1.nets.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn1.weight', '_dummy_variable', 'mask_generator._dummy_variable', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.1.temperature', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn2.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.1.pos_y', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.5.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.bn1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.6.0.downsample.0.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.conv2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.7.1.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.downsample.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.5.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn1.bias', 'obs_encoder.obs_nets.image.nets.0.nets.7.0.conv1.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.1.bn2.weight', 'obs_encoder.obs_nets.image.nets.0.nets.4.0.bn2.bias'}\"\n",
    ")\n",
    "if len(missing_keys) != 0:\n",
    "    print(\"MISSING KEYS\")\n",
    "    print(missing_keys)\n",
    "if unexpected_keys != allowed_unexpected_keys:\n",
    "    print(\"UNEXPECTED KEYS\")\n",
    "    print(unexpected_keys)\n",
    "\n",
    "if len(missing_keys) != 0 or unexpected_keys != allowed_unexpected_keys:\n",
    "    print(\"Failed due to mismatch in state dicts.\")\n",
    "    exit()\n",
    "\n",
    "torch.save(policy.state_dict(), \"/tmp/policy.pt\")\n",
    "policy.save_pretrained(PATH_TO_SAVE_NEW_WEIGHTS)\n",
    "OmegaConf.save(cfg, Path(PATH_TO_SAVE_NEW_WEIGHTS) / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.envs.factory import make_env\n",
    "from lerobot.scripts.eval import eval_policy\n",
    "env = make_env(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_sum_reward': 10.811818440497525, 'avg_max_reward': 0.09880081223534598, 'pc_success': 0.0, 'eval_s': 110.97826099395752, 'eval_ep_s': 2.219565234184265}\n"
     ]
    }
   ],
   "source": [
    "#Eval\n",
    "from lerobot.common.envs.factory import make_env\n",
    "from lerobot.scripts.eval import eval_policy\n",
    "env = make_env(cfg)\n",
    "with torch.no_grad():\n",
    "    info = eval_policy(\n",
    "        env,\n",
    "        policy,\n",
    "        cfg.eval.n_episodes,\n",
    "        max_episodes_rendered=10,\n",
    "        videos_dir=Path(\"./\"),\n",
    "        start_seed=cfg.seed,\n",
    "    )\n",
    "print(info[\"aggregated\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
